import librosa
import json
import numpy as np

def generate_chart_from_audio(audio_path, bpm, output_json_path, latency=0.35):
    print(f"Loading audio file: {audio_path}")
    y, sr = librosa.load(audio_path, sr=None)
    print(f"Sample rate: {sr}, Total samples: {len(y)}")

    # Compute the tempo and beat frames
    tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr, bpm=bpm)
    print(f"Detected tempo: {tempo}")
    print(f"Number of beat frames: {len(beat_frames)}")

    # Convert beat frames to time
    beat_times = librosa.frames_to_time(beat_frames, sr=sr)
    print(f"Number of beat times: {len(beat_times)}")

    # Detect onset frames (when sounds occur)
    onset_frames = librosa.onset.onset_detect(y=y, sr=sr, units='time')
    print(f"Number of onset frames detected: {len(onset_frames)}")

    # Create a chart based on detected beats and onsets
    chart_data = []
    sixteenth_note_duration = 60 / (bpm * 4)
    print(f"Sixteenth note duration: {sixteenth_note_duration} seconds")

    for i, time in enumerate(onset_frames):
        adjusted_time = time - latency
        note_time = round(adjusted_time / sixteenth_note_duration) * sixteenth_note_duration
        key = np.random.choice(["a", "s", "k", "l"])
        chart_data.append({"key": key, "time": round(note_time, 2)})
        print(f"Note {i+1}: Key={key}, Adjusted Time={adjusted_time}, Quantized Time={note_time}")

    # Save the chart to a JSON file
    with open(output_json_path, "w") as file:
        json.dump(chart_data, file, indent=4)

    print(f"Chart generated and saved to {output_json_path}")

# Example usage
audio_path = "Icicles_AzakaelasRemix_Mix2.wav"
bpm = 105
output_json_path = "Icicles.json"
latency = 0.7
generate_chart_from_audio(audio_path, bpm, output_json_path, latency)
